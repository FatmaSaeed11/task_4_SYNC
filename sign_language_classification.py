# -*- coding: utf-8 -*-
"""Sign Language Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11pNngCPpyEHl80SBPqE4UTwwT-Qfup-G

load our data from kaggle
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d datamunge/sign-language-mnist

from zipfile import ZipFile
dataset='/content/sign-language-mnist.zip'
with ZipFile(dataset,'r') as zip:
  zip.extractall()
  print('the dataset is extracted')

"""import important libraries"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import seaborn as sns

"""extract our data"""

train_data=pd.read_csv('/content/sign_mnist_train/sign_mnist_train.csv')
test_data=pd.read_csv('/content/sign_mnist_test/sign_mnist_test.csv')

# len_data
print(len(train_data))

print(len(test_data))

"""convert dataset to np array"""

train_np=np.array(train_data,dtype='float32')
test_np=np.array(test_data,dtype='float32')

"""labeling"""

class_names=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']

"""check and plot images"""

im=random.randint(1,train_data.shape[0])

fig1,ax1=plt.subplots(figsize=(2,2))
plt.imshow(train_np[im,1:].reshape((28,28)),cmap='gray')
print("Lable for the image is:",class_names[int(train_np[im,0])])

"""normalization"""

x_train=train_np[:,1:]/255.
x_test=test_np[:,1:]/255.

"""catigorical our lables"""

y_train=train_np[:,0]
y_train_cat=to_categorical(y_train,num_classes=25)

y_test=test_np[:,0]
y_test_cat=to_categorical(y_test,num_classes=25)

"""reshape"""

x_train=x_train.reshape(x_train.shape[0],*(28,28,1))
x_test=x_test.reshape(x_test.shape[0],*(28,28,1))

"""Bild model"""

model=Sequential()
model.add(Conv2D(32,(3,3),input_shape=(28,28,1),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))
model.add(Conv2D(64,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))
model.add(Conv2D(128,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(128,activation='relu'))
model.add(Dense(25,activation='softmax'))

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

model.summary()

history=model.fit(x_train,y_train_cat,batch_size=128,epochs=10,verbose=1,validation_data=(x_test,y_test_cat))

"""Accuracy"""

loss=history.history['loss']
val_loss=history.history['val_loss']
epochs=range(1,len(loss)+1)
plt.plot(epochs,loss,'y',label='Training loss')
plt.plot(epochs,val_loss,'y',label='validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('LOss')
plt.legend()
plt.show()

accuracy=history.history['accuracy']
val_accuracy=history.history['val_accuracy']

plt.plot(epochs,accuracy,'y',label='Training accuracy')
plt.plot(epochs,val_accuracy,'y',label='validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""Prediction"""

prediction=model.predict(x_test)

im=random.randint(1,len(prediction))
plt.imshow(x_test[im,:,:,0])
print("Lable for the image is:",class_names[int(prediction[im,24])])
print("True Lable is:",class_names[int(y_test[im])])

im=random.randint(1,len(prediction))
plt.imshow(x_test[im,:,:,0])
print("Lable for the image is:",class_names[int(prediction[im,24])])
print("True Lable is:",class_names[int(y_test[im])])